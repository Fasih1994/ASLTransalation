{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASL Handshape Data\n",
    "\n",
    "## Description of data\n",
    "Link to data found on Nicolas Pugeault's website\n",
    "(http://empslocal.ex.ac.uk/people/staff/np331/index.php?section=FingerSpellingDataset). The dataset is of 24 static handshapes corresponding to English letters (excluding the letters \"J\" and \"Z\" since they require motion). The data comprises of 5 different non-native signers of about 60,000 RGB (intensity) images and depth images. The images have some rotational variance as the subject moved their hand during the image capture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup\n",
    "\n",
    "Run this section if data is already partially processed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image \n",
    "from functools import reduce\n",
    "\n",
    "## Variables needed for reference throughout sections\n",
    "dataset_url = 'www.cvssp.org/FingerSpellingKinect2011/fingerspelling5.tar.bz2'\n",
    "filename = 'fingerspelling5.tar.bz2'\n",
    "# Data directory\n",
    "final_data_dir = 'dataset'\n",
    "# Data's top-level directory (after download & decompreshion)\n",
    "dataset_dir = 'dataset5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing data\n",
    "\n",
    "Below is a script to download the data to the local machine. Note that compressed file is over 2GB. If the data was already retrieved, you can skip this section and start with the preprocessing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link to dataset and \n",
    "os.system('wget {URL}'.format(URL=dataset_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncompress\n",
    "os.system('tar xjf {}'.format(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing and relabelling data\n",
    "\n",
    "Only RGB image data is needed and should be relabelled so that the files can be easily be placed into one directory but still contain metadata for classification, validation, and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new data directory if doesn't exist\n",
    "if not os.path.exists(final_data_dir):\n",
    "    os.makedirs(final_data_dir)\n",
    "\n",
    "# Define patterns for depth files & RGB files \n",
    "# Format: `depth_0_0528.png` & `color_12_0137.png`\n",
    "pattern_depth_file = '(depth\\w*.png)'\n",
    "pattern_rgb_file = 'color_\\d*_(\\d*).png'\n",
    "# Number of files renamed/delted\n",
    "n_del, n_rename = 0,0\n",
    "\n",
    "# Save that this is a new subject (numerical since letter can be confusing)\n",
    "# Each subject in directory with a letter ('A','B','C',...)\n",
    "for (subject_id, subject_dir) in enumerate(os.listdir(dataset_dir)):\n",
    "    # Directories for each letter (excluding \"j\" & \"z\")\n",
    "    path_to_subject = os.path.join(dataset_dir, subject_dir)\n",
    "    \n",
    "    for letter_dir in os.listdir(path_to_subject):\n",
    "        # Use letter as number ('a' starts @ 00)\n",
    "        letter_id = ord(letter_dir.lower()) - ord(('a'))\n",
    "        letter_id = f'0{letter_id}' if letter_id < 10 else letter_id\n",
    "        path_to_letter = os.path.join(path_to_subject, letter_dir)\n",
    "        \n",
    "        for image_file in os.listdir(path_to_letter):\n",
    "            # Remove depth file\n",
    "            if re.search(pattern_depth_file, image_file):\n",
    "                path_depth_file = os.path.join(path_to_letter, image_file)\n",
    "                os.remove(path_depth_file)\n",
    "                # Inform depth file removed\n",
    "                print(f'\\r#{n_del}: Depth file deleted {path_depth_file}', end='')\n",
    "                n_del += 1\n",
    "            else:\n",
    "                # Get ID of each file (None if not matched)\n",
    "                num_id = re.match(pattern_rgb_file, image_file)\n",
    "                if num_id:\n",
    "                    # Get the matching parathesis only\n",
    "                    num_id = num_id.group(1)\n",
    "                    path_image_file = os.path.join(path_to_letter, image_file)\n",
    "                    # Rename image\n",
    "                    new_image_name = f'{letter_id}_{subject_id}_{num_id}.png'\n",
    "                    new_path_image_file = os.path.join(final_data_dir, new_image_name)\n",
    "                    os.rename(path_image_file, new_path_image_file)\n",
    "                    # Inform image renamed\n",
    "                    print(f'\\r#{n_rename}: {new_path_image_file} renamed from {path_image_file}', end='')\n",
    "                    n_rename += 1\n",
    "            sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change images to grayscale\n",
    "\n",
    "RGB images will be turned into grayscale since color shouldn't be necessary for recognition. This also should reduce the file sizes of the images and can help generalize to future datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image to grayscale and save file\n",
    "def img_to_gray(img_file):\n",
    "    img_path = os.path.join(final_data_dir, img_file)\n",
    "    img = Image.open(img_path, 'r').convert('L')\n",
    "    img.save(img_path)\n",
    "    \n",
    "# Keep track of image number\n",
    "n = 0 \n",
    "file_list = [x if re.search('*png', x) for x in os.listdir(final_data_dir)]\n",
    "n_imgs = len(file_list)\n",
    "errors_convert = []\n",
    "\n",
    "# Iterate over each image\n",
    "for img_filename in file_list:\n",
    "    print(f'\\r#{n: <5} of {n_imgs}: Converting image `{img_filename}` to gray', end='')\n",
    "    # Keep track of files that were not successfully converted\n",
    "    try:\n",
    "        img_to_gray(img_filename)\n",
    "    except:\n",
    "        errors_convert.append((n,img_filename))\n",
    "        print(f'`{img_filename}` was NOT converted')\n",
    "    n += 1\n",
    "    sys.stdout.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
