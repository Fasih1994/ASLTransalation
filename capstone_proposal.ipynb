{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Capstone Proposal\n",
    "Victor Geislinger  \n",
    "2018 Month Day\n",
    "\n",
    "## American Sign Language Handshape Detection from Static Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Background\n",
    "> _(approx. 1-2 paragraphs)_\n",
    ">\n",
    "> In this section, provide brief details on the background information of the domain from which the project is proposed. Historical information relevant to the project should be included. It should be clear how or why a problem in the domain can or should be solved. Related academic research should be appropriately cited in this section, including why that research is relevant. Additionally, a discussion of your personal motivation for investigating a particular problem in the domain is encouraged but not required.\n",
    "\n",
    "American Sign Language (ASL) is a sign language that does not use speech to communicate and is mostly used by the American Deaf population. Though used throughout the English-speaking United States, it is in fact it's own language seperate from English and relies on creating the language's syntax with multiple visuals such as handshapes, movement, position, and nonmanual markers. Although there are many variations of sign language specific to different languages, regions, and needs, being able to use a computer to detect ASL would be extremely useful in not only ASL translation but also other sign language translations as well as non-language geusture recognition.\n",
    "  \n",
    "There has been past research in detecting ASL or ASL-like handshapes and movements such as gesture recognition. There have been past attempts in detecting hand motions and handshapes that use datasets with depth information using sensors like the Microsoft Kinnect. However, the technology required for this type of data is relatively uncommon compared to the ubiquitous  camera sensor found on nearly every computer and phone. The recent advances in image recognition and classification make the concept of detecting and classifying ASL handshapes to be attainable through video or static images (possibly taken from video). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "> _(approx. 1 paragraph)_\n",
    "> \n",
    "> In this section, clearly describe the problem that is to be solved. The problem described should be well defined and should have at least one relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable (the problem can be expressed in mathematical or logical terms) , measurable (the problem can be measured by some metric and clearly observed), and replicable (the problem can be reproduced and occurs more than once).\n",
    "\n",
    "In this project I will classify static images of different ASL handshapes. This is a good stepping stone before a video dataset is used in future projects/research since time dependence and movement will not have to be considered. My solution could be compared to classifying the MNIST handwritten database but with images of ASL handshapes. Deep learning could be used to classify the images. The model could then be evaluated with a validation set and/or new images from a similarly preproccessed but independent dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets and Inputs\n",
    ">_(approx. 2-3 paragraphs)_\n",
    ">\n",
    ">In this section, the dataset(s) and/or input(s) being considered for the project should be thoroughly described, such as how they relate to the problem and why they should be used. Information such as how the dataset or input is (was) obtained, and the characteristics of the dataset or input, should be included with relevant references and citations as necessary It should be clear how the dataset(s) or input(s) will be used in the project and whether their use is appropriate given the context of the problem.\n",
    "\n",
    "The prefered dataset I will be using the ASL FingerSpelling Dataset from the University of Surreyâ€™s Center for Vision, Speech and Signal Processing (http://empslocal.ex.ac.uk/people/staff/np331/index.php?section=FingerSpellingDataset). This dataset contains both colored images and depth sensing data collected from a Microsoft Kinnect. (Note that I will not be using the depth sensing data since my project will be focused on using static images.) The images are in color and include 24 different handshapes each representing a letter from the English alphabet; note \"j\" and \"z\" are excluded since these letters are dependent on movement and therefore don't have a static image representation. \n",
    "\n",
    "The images have been cropped around the handshape though each cropping results in a differently sized image fitting within a 200x200 window with a resolution of 72 pixels per inch. The background behind the handshape is not uniform or consistent. The dataset contains approximately 48,0000 images generated by 5 different non-native ASL signers with over 500 samples of each of the 24 different handshapes. The handshapes in the image feature some rotational differences as the subject was instructed to adjust hand position for the camera.\n",
    "\n",
    "<!-- Kaggle dataset has incorrect ASL handshapes which wouldn't translate to other data with actual ASL handshapes\n",
    "The secondary dataset which could be used for validation is from Kaggle called \"Sign Langauge MNIST\" (https://www.kaggle.com/datamunge/sign-language-mnist/home). This dataset is of gray-scaled images of 24 different handshapes each representing a letter from the English alphabet; note \"j\" and \"z\" are excluded since these letters are dependent on movement and those don't have a static image representation. All images have been cropped around the handshape to a square 28x28 pixels. Dataset was produced by 7 different non-native signers each with 10 instances of the 24 handshapes, making a total of 1680 images. The images were then used to create 50+ variations.\n",
    "-->\n",
    "\n",
    "<!-- Other datasets available \n",
    "- Possible other datasets (video,depth,images) http://facundoq.github.io/unlp/sign_language_datasets/index.html\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Statement\n",
    ">_(approx. 1 paragraph)_\n",
    ">\n",
    ">In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Additionally, describe the solution thoroughly such that it is clear that the solution is quantifiable (the solution can be expressed in mathematical or logical terms) , measurable (the solution can be measured by some metric and clearly observed), and replicable (the solution can be reproduced and occurs more than once).\n",
    "\n",
    "Deep learning will be used to classify the different handshape images, specifically using a convolutional neural network (CNN) as it has been historically been effective in many image recognition tasks. Transfer learning from previously trained models like VGG-16 can be used to help with the efficiency of this task. The data to be used already has been cropped with inconsistently around the handshape so the images will have to be resized for the model's CNN architecture to function. The data can be used for training and testing via a 80-20 split respectively. The results can be presented as a confusion matrix of the 24 different handshapes and the precision calculated to gauge its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Model\n",
    ">_(approximately 1-2 paragraphs)_\n",
    ">\n",
    ">In this section, provide the details for a benchmark model or result that relates to the domain, problem statement, and intended solution. Ideally, the benchmark model or result contextualizes existing methods or known information in the domain and problem given, which could then be objectively compared to the solution. Describe how the benchmark model or result is measurable (can be measured by some metric and clearly observed) with thorough detail.\n",
    "  \n",
    "The first and simplest benchmark will be comparing the developed model with a random choice model. With each handshape being equally likely, we would expect the random choice model to only identify the handshape $\\frac{1}{24}\\approx$ 4.2% of the time on average. \n",
    "\n",
    "  \n",
    "A goal of this project is to achieve better performance than if specialized equipment other than a camera to take images were to be used (like the Microsoft Kinnect). We can then use the performance from the \"Spelling It Out\" paper of their random forrest model as our idealized benchmark. Observing the paper's confusion matrix which used 4 of the users to train and validate the model and 1 user to test performance, similar handshapes were misclassified with the handshapes least correctly identified being \"T\", \"O\", \"S\", and \"M\" (7%, 13%, 17%, and 17% of the time correctly identified respectively). The handshapes that were identified the best were \"L\", \"V\", \"B\", and \"G\" (87%, 87%, 83%, and 80% of the time correctly identified respectively). The paper's model achieved an overall mean precision of 73% and 75% using only the images and using both images and  depth data respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    ">_(approx. 1-2 paragraphs)_\n",
    ">\n",
    ">In this section, propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms).\n",
    "\n",
    "\n",
    "- Use mean squared error (MSE) $MSE= \\frac{1}{m} \\sum(y_i - \\hat{y}_i)$\n",
    "- Use F1 score since we want precision and recall about the same. That is not classifying a letter is just as bad as misclassifying a letter\n",
    "    - $F_\\beta = (1+\\beta^2) \\frac{precision \\times recall}{(\\beta^2 \\times precision) + recall}$\n",
    "    - $F_1 = 2 \\frac{precision \\times recall}{precision + recall}$\n",
    "    - $recall = \\frac{pos_{true}}{pos_{true} + neg_{false}}$\n",
    "    - $precision = \\frac{pos_{true}}{pos_{true} + pos_{false}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Design\n",
    ">_(approx. 1 page)_\n",
    ">\n",
    ">In this final section, summarize a theoretical workflow for approaching a solution given the problem. Provide thorough discussion for what strategies you may consider employing, what analysis of the data might be required before being used, or which algorithms will be considered for your implementation. The workflow and discussion that you provide should align with the qualities of the previous sections. Additionally, you are encouraged to include small visualizations, pseudocode, or diagrams to aid in describing the project design, but it is not required. The discussion should clearly outline your intended workflow of the capstone project.\n",
    "\n",
    "-----------\n",
    "\n",
    "**Before submitting your proposal, ask yourself. . .**\n",
    "\n",
    "- Does the proposal you have written follow a well-organized structure similar to that of the project template?\n",
    "- Is each section (particularly **Solution Statement** and **Project Design**) written in a clear, concise and specific fashion? Are there any ambiguous terms or phrases that need clarification?\n",
    "- Would the intended audience of your project be able to understand your proposal?\n",
    "- Have you properly proofread your proposal to assure there are minimal grammatical and spelling mistakes?\n",
    "- Are all the resources used for this project correctly cited and referenced?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
