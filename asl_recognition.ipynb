{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# American Sign Language (ASL) Image Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "\n",
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing data into training, validation, and testing sets\n",
    "\n",
    "Now that preprocessing the images is completed (see `data_preprocessing.ipynb` notebook), the full dataset will be split into training, validation, and testing sets. The testing set will be all the images from one subject to mirror the \"Spelling It Out\" paper's method so the benchmark model can be compared. The rest of the images will be randomly split; 80% of images for training, 20% of the images for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, n_categories=24):\n",
    "    data = load_files(path)\n",
    "    image_files = np.array(data['filenames'])\n",
    "    # Hot encode categories to matrix\n",
    "    image_targets = np_utils.to_categorical(np.array(data['target']), n_categories)\n",
    "    return image_files, image_targets\n",
    "\n",
    "def move_data_by_category(container_dir, regex_file_format='.*png'):\n",
    "    '''Move data into a directory based on category'''\n",
    "    # Still check if files are images\n",
    "    file_list = [x for x in os.listdir(container_dir) if re.search(regex_file_format, x)]\n",
    "    # Get numerical string (note that 1 digits are represented w/ 2 digits) \n",
    "    letters = {x.split('_')[0] for x in file_list}\n",
    "    \n",
    "    for letter in letters:\n",
    "        # Only images that match letter\n",
    "        images_with_letter = [filename for filename in file_list if filename.split('_')[0] == letter]\n",
    "        # Add images to sub directory\n",
    "        new_categ_path = os.path.join(container_dir, letter)\n",
    "        if not os.path.exists(new_categ_path):\n",
    "            os.makedirs(new_categ_path)\n",
    "        print(f'Created {new_categ_path} dir with {len(images_with_letter)} items')\n",
    "        for img_filename in images_with_letter:\n",
    "            path = os.path.join(container_dir, img_filename)\n",
    "            new_path = os.path.join(new_categ_path, img_filename)            \n",
    "            os.rename(path, new_path)\n",
    "    # TODO: Check if any files were skipped (improperly named?)\n",
    "        \n",
    "\n",
    "def get_testing_data(data_dir, subject_num='4'):\n",
    "    '''Get all data/images pertaining to one subject'''\n",
    "    # Only search in directory for images with that subject\n",
    "    file_list = [x for x in os.listdir(data_dir) if re.search(f'\\d+_{subject_num}_\\d*\\.png', x)]\n",
    "    \n",
    "    # Make a new testing data directory if doesn't exist\n",
    "    testing_dir = os.path.join(data_dir, 'test')\n",
    "    if not os.path.exists(testing_dir):\n",
    "        os.makedirs(testing_dir)\n",
    "        \n",
    "    # Move images of particular subject into testing directory\n",
    "    for image_filename in file_list:\n",
    "        # file is **_n_****.png where n is an integer representing a subject\n",
    "        _, subject, _ = image_filename.split('_')\n",
    "        # Move file into testing directory\n",
    "        path = os.path.join(data_dir, image_filename)\n",
    "        new_path = os.path.join(testing_dir, image_filename)\n",
    "        os.rename(path, new_path)\n",
    "        \n",
    "    # Move each image file's numerical str representing letters found in testing into own category directory\n",
    "    move_data_by_category(testing_dir)\n",
    "    \n",
    "    return load_dataset(testing_dir)\n",
    "\n",
    "\n",
    "def get_training_validation_data(data_dir, ratio=0.8):\n",
    "    '''Randomly split data into training and validation sets'''\n",
    "    # Only search in directory for images\n",
    "    file_list = [x for x in os.listdir(data_dir) if re.search('.*png', x)]\n",
    "    \n",
    "    # Make a new training & validation data directory if doesn't exist\n",
    "    train_dir = os.path.join(data_dir, 'train')\n",
    "    valid_dir = os.path.join(data_dir, 'valid')\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir)\n",
    "    if not os.path.exists(valid_dir):\n",
    "        os.makedirs(valid_dir)\n",
    "        \n",
    "    # Randomly split file list into training and vaidation sets\n",
    "    np.random.shuffle(file_list)\n",
    "    split_int = int(ratio * len(file_list))\n",
    "    train_list = file_list[:split_int]\n",
    "    valid_list = file_list[split_int:]\n",
    "    \n",
    "    # Move images of particular subject into testing directory\n",
    "    for filenames, new_dir in [(train_list, train_dir), (valid_list, valid_dir)]:\n",
    "        for image_filename in filenames:\n",
    "            # Move file into testing directory\n",
    "            path = os.path.join(data_dir, image_filename)\n",
    "            new_path = os.path.join(new_dir, image_filename)\n",
    "            os.rename(path, new_path)\n",
    "\n",
    "        # Move each image file's numerical str representing letters found in testing into own category directory\n",
    "        move_data_by_category(new_dir)\n",
    "    \n",
    "    return (load_dataset(train_dir), load_dataset(valid_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_target = get_testing_data(data_dir)\n",
    "train, valid = get_training_validation_data(data_dir)\n",
    "# Separated data and its targets\n",
    "train_data, train_taget = train\n",
    "valid_data, valid_taget = valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(8675309)\n",
    "%matplotlib inline\n",
    "\n",
    "# Display image previews below\n",
    "plt.figure(figsize=(20,55))\n",
    "columns = 8\n",
    "n = 1\n",
    "\n",
    "# Randomly choose images to display (with label)\n",
    "for image_path in np.random.choice(train_data, 24, replace=False):\n",
    "    img = Image.open(image_path)\n",
    "    plt.subplot(20, columns, n)\n",
    "    n+=1\n",
    "    plt.imshow(img)\n",
    "    letter = image_path.split('/')[-1][:2]\n",
    "    letter = chr(int(letter)+65)\n",
    "    plt.title(letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
